{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71d6d727",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import random\n",
    "from matplotlib import pyplot\n",
    "from matplotlib import colors\n",
    "from matplotlib import font_manager\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.ticker as mticker\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.lines as mlines\n",
    "import datetime\n",
    "import cartopy.crs\n",
    "from cartopy.mpl.gridliner import LATITUDE_FORMATTER, LONGITUDE_FORMATTER\n",
    "from PIL import Image\n",
    "import pandas\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import seaborn\n",
    "import scipy\n",
    "from scipy import stats\n",
    "from scipy.stats import poisson, ttest_ind\n",
    "from scipy import linalg\n",
    "import xarray as xr\n",
    "import netCDF4\n",
    "import cftime\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa34a856",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Directory\n",
    "Diri = \"data/orig/\"\n",
    "\n",
    "#\n",
    "# Define Variables of Research\n",
    "# Near Surface Air Temperature\n",
    "Var1 = \"tas\"\n",
    "Temp_Files = os.listdir(Diri+Var1+\"/global/\")\n",
    "# Net Radiative Flux at Top of Atmosphere\n",
    "Var2 = \"netTOA\"\n",
    "Net_TOA_Files = os.listdir(Diri+Var2+\"/global/\")\n",
    "# Precipitation\n",
    "Var3 = \"pr\"\n",
    "Precip_Files = os.listdir(Diri+Var3+\"/global/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02ec6320",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open Temperature Files\n",
    "for File in Temp_Files:\n",
    "    Parts = File.split(\"_\")\n",
    "    Model = Parts[1]\n",
    "    Experiment = Parts[2]\n",
    "    Time = Parts[3].split(\".\")[0]\n",
    "    if Time==\"150\":\n",
    "        Temp_Files.remove(File)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b3c9db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List and Open Net Top of Atmosphere Radiation Files\n",
    "for File in Net_TOA_Files: \n",
    "#    print(File)\n",
    "    Parts = File.split(\"_\")\n",
    "    Model = Parts[1]\n",
    "    Experiment = Parts[2]\n",
    "    Time = Parts[3].split(\".\")[0]\n",
    "#    print(Time)\n",
    "    if Time==\"150\":\n",
    "#        print(\"Remove model\")\n",
    "        Net_TOA_Files.remove(File)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38145752",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open Precipitation Files\n",
    "for File in Precip_Files:\n",
    "    Parts = File.split(\"_\")\n",
    "    Model = Parts[1]\n",
    "    Experiment = Parts[2]\n",
    "    Time = Parts[3].split(\".\")[0]\n",
    "    if Time==\"150\":\n",
    "        Precip_Files.remove(File)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "080264f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'MPIESM12': ['abrupt4x'], 'GISSE2R': ['abrupt4x'], 'IPSLCM5A': ['abrupt4x'], 'CCSM3': ['abrupt4x'], 'HadGEM2': ['abrupt4x'], 'CESM104': ['abrupt4x'], 'CCSM3II': ['abrupt1400ppm'], 'ECHAM5MPIOM': ['abrupt4x'], 'FAMOUS': ['abrupt4x'], 'CNRMCM61': ['abrupt4x'], 'HadCM3L': ['abrupt4x'], 'MPIESM11': ['abrupt4x']}\n"
     ]
    }
   ],
   "source": [
    "# Create Pertubations Library\n",
    "Perturbations = {} \n",
    "for File in Temp_Files: \n",
    "    Parts = File.split(\"_\")\n",
    "    Model = Parts[1]\n",
    "    Experiment = Parts[2]\n",
    "    if Experiment!=\"control\": \n",
    "        if Model in list(Perturbations):\n",
    "            Perturbations[Model].append(Experiment)\n",
    "        else:\n",
    "            Perturbations[Model] = [Experiment]\n",
    "print (Perturbations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a7485d5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'MPIESM12': 'abrupt4x', 'GISSE2R': 'abrupt4x', 'IPSLCM5A': 'abrupt4x', 'CCSM3': 'abrupt4x', 'HadGEM2': 'abrupt4x', 'CESM104': 'abrupt4x', 'CCSM3II': 'abrupt1400ppm', 'ECHAM5MPIOM': 'abrupt4x', 'FAMOUS': 'abrupt4x', 'CNRMCM61': 'abrupt4x', 'HadCM3L': 'abrupt4x', 'MPIESM11': 'abrupt4x'}\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "# Create Abrupt 4x Pertubations Library\n",
    "Pert_4x = {}\n",
    "for File in Temp_Files: \n",
    "    Parts = File.split(\"_\")\n",
    "    Model = Parts[1]\n",
    "    Experiment = Parts[2]\n",
    "    if Experiment!=\"control\": \n",
    "        if Experiment==\"abrupt4x\" or Experiment==\"abrupt1400ppm\":\n",
    "            Pert_4x[Model] = Experiment\n",
    "print (Pert_4x)\n",
    "#\n",
    "# Define Number of Datasets\n",
    "Num_Datasets = len(Pert_4x)\n",
    "print (Num_Datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "70084ba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['MPIESM12', 'MPIESM11', 'IPSLCM5A', 'HadGEM2', 'HadCM3L', 'GISSE2R', 'FAMOUS', 'ECHAM5MPIOM', 'CNRMCM61', 'CESM104', 'CCSM3II', 'CCSM3']\n"
     ]
    }
   ],
   "source": [
    "# Create List of Models\n",
    "#Model_List = []\n",
    "#for Model in list(Pert_4x):\n",
    "#    Model_List.append(Model)\n",
    "Model_List = ['MPIESM12', 'MPIESM11', 'IPSLCM5A', 'HadGEM2', 'HadCM3L', 'GISSE2R', 'FAMOUS', 'ECHAM5MPIOM', \\\n",
    "'CNRMCM61', 'CESM104', 'CCSM3II', 'CCSM3']\n",
    "print (Model_List)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "74a3df80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Function to Open Temperature Files\n",
    "def Open_Temp_Files(Temp_Files, Model):\n",
    "# Open Temperature Control Files\n",
    "    Temp_Control_Filename = [i for i in Temp_Files if i.startswith(\"tas_\"+Model+\"_\"+\"control\"+\"_\")][0]\n",
    "    Temp_Control_Data = xr.open_dataset(Diri+\"tas/global/\"+Temp_Control_Filename)\n",
    "    Temp_Control = Temp_Control_Data.tas\n",
    "    Years_Control = range(len(Temp_Control))\n",
    "#\n",
    "# Open Temperature 4x Files\n",
    "    Temp_4x_Filename = [i for i in Temp_Files if i.startswith(\"tas_\"+Model+\"_\"+Pert_4x[Model]+\"_\")][0]\n",
    "    Temp_4x_Data = xr.open_dataset(Diri+\"tas/global/\"+Temp_4x_Filename)\n",
    "    Temp_4x = Temp_4x_Data.tas\n",
    "    Years_4x = range(len(Temp_4x))\n",
    "#\n",
    "# Return Results\n",
    "    return (Temp_Control, Years_Control, Temp_4x, Years_4x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5540b53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Function to Create Smoothen Temperature 4x and Control Lines\n",
    "def Temp_Smooth(Temp_Control, Years_Control, Temp_4x, Years_4x, Model):\n",
    "### Take the difference of each time step to the time-averaged control simulation imbalance\n",
    "    Temp_Control_Smooth = Temp_Control.mean() + Temp_4x*0\n",
    "#\n",
    "# Return Results\n",
    "    return (Temp_Control_Smooth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e2e29054",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Function to Open Net TOA Files\n",
    "def Open_Net_TOA_Files(Net_TOA_Files, Model):\n",
    "# Open Net TOA Control Files\n",
    "    Net_TOA_Control_Filename = [i for i in Net_TOA_Files if i.startswith(\"netTOA_\"+Model+\"_\"+\"control\"+\"_\")][0]\n",
    "    Net_TOA_Control_Data = xr.open_dataset(Diri+\"netTOA/global/\"+Net_TOA_Control_Filename)\n",
    "    Net_TOA_Control_Data[\"netTOA\"][Net_TOA_Control_Data[\"netTOA\"] < 0] = numpy.nan\n",
    "    Net_TOA_Control = Net_TOA_Control_Data.netTOA\n",
    "    Net_TOA_Control[Net_TOA_Control < 0] = numpy.nan\n",
    "    Years_Control = range(len(Net_TOA_Control))\n",
    "    Years_Control = numpy.array(Years_Control)\n",
    "#\n",
    "# Open Net TOA 4x Files\n",
    "    Net_TOA_4x_Filename = [i for i in Net_TOA_Files if i.startswith(\"netTOA_\"+Model+\"_\"+Pert_4x[Model]+\"_\")][0]\n",
    "    Net_TOA_4x_Data = xr.open_dataset(Diri+\"netTOA/global/\"+Net_TOA_4x_Filename)\n",
    "    Net_TOA_4x = Net_TOA_4x_Data.netTOA\n",
    "    Years_4x = range(len(Net_TOA_4x))\n",
    "#\n",
    "# Return Results\n",
    "    return (Net_TOA_Control, Years_Control, Net_TOA_4x, Years_4x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "deef623e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Function to Create Smoothen Net TOA 4x and Control Lines\n",
    "def Net_TOA_Smooth(Net_TOA_Control, Years_Control, Net_TOA_4x, Years_4x, Model):\n",
    "### Atmospheric variable anomal - removing imbalances in the control and drift\n",
    "### (Rugenstein et al 2019, BAMS - section 3a, fig 3)\n",
    "### Take the difference of each time step to the time-averaged control simulation imbalance\n",
    "    Net_TOA_Control_Smooth = Net_TOA_Control.mean() + Net_TOA_4x*0\n",
    "#\n",
    "# Return Results\n",
    "    return (Net_TOA_Control_Smooth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a947832b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Function to Open Precipitation Files\n",
    "def Open_Precip_Files(Precip_Files, Model):\n",
    "# Open Precipitation Control Files\n",
    "    Precip_Control_Filename = [i for i in Precip_Files if i.startswith(\"pr_\"+Model+\"_\"+\"control\"+\"_\")][0]\n",
    "    Precip_Control_Data = xr.open_dataset(Diri+\"pr/global/\"+Precip_Control_Filename)\n",
    "    Precip_Control_Data[\"pr\"][Precip_Control_Data[\"pr\"] < 0] = numpy.nan\n",
    "    Precip_Control = Precip_Control_Data.pr\n",
    "    Precip_Control[Precip_Control < 0] = numpy.nan\n",
    "    Years_Control = range(len(Precip_Control))\n",
    "#\n",
    "# Open Precipitation 4x Files\n",
    "    Precip_4x_Filename = [i for i in Precip_Files if i.startswith(\"pr_\"+Model+\"_\"+Pert_4x[Model]+\"_\")][0]\n",
    "    Precip_4x_Data = xr.open_dataset(Diri+\"pr/global/\"+Precip_4x_Filename)\n",
    "    Precip_4x = Precip_4x_Data.pr\n",
    "    Years_4x = range(len(Precip_4x))\n",
    "#\n",
    "# Return Results\n",
    "    return (Precip_Control, Years_Control, Precip_4x, Years_4x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "24b3a069",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Function to Create Smoothen Precipitation 4x and Control Lines\n",
    "L_Vapour = 2.5 * 10**6\n",
    "def Precip_Smooth(Precip_Control, Years_Control, Precip_4x, Years_4x, Model):\n",
    "### Atmospheric variable anomal - removing imbalances in the control and drift\n",
    "### (Rugenstein et al 2019, BAMS - section 3a, fig 3)\n",
    "### Take the difference of each time step to the time-averaged control simulation imbalance\n",
    "    Precip_Control_Smooth = Precip_Control.mean() + Precip_4x*0\n",
    "#\n",
    "# Return Results\n",
    "    return (Precip_Control_Smooth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "758a1072",
   "metadata": {},
   "outputs": [],
   "source": [
    "def AutocorLone(x):\n",
    "    a = numpy.ma.masked_invalid(x[:-1])\n",
    "    b = numpy.ma.masked_invalid(x[1:])\n",
    "    msk = (~a.mask & ~b.mask)\n",
    "    ac = numpy.ma.corrcoef(a[msk],b[msk])[0,1]\n",
    "    #print(ac)\n",
    "    return ac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3e1687d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Detrend(x):\n",
    "    xc = x - x.mean()\n",
    "    t = numpy.arange(len(x))\n",
    "    tc = t - t.mean()\n",
    "    slope, intercept, r_value, p_value, std_err = stats.linregress(tc,xc)\n",
    "### Maybe I need to include the intercept here if it's nonzero? \n",
    "    xdc = xc - slope*tc\n",
    "    return xdc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e5bb10a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Corr_IgnoreNaN(x,y):\n",
    "    a = numpy.ma.masked_invalid(x)\n",
    "    b = numpy.ma.masked_invalid(y)\n",
    "    msk = (~a.mask & ~b.mask)\n",
    "    c = numpy.ma.corrcoef(a[msk],b[msk])[0,1]\n",
    "    #print(ac)\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "493d96c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CalcParams_Fixed_iv(xdat,sxi,ydat,syi,pit):\n",
    "    \"\"\"\n",
    "    Calculate the parameters, both intercepts as well as the slope of the regression\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # backwards compatibility with calcparams\n",
    "\n",
    "    [sxi,syi,pit]=Backwards_Compat(sxi,syi,pit)\n",
    "\n",
    "        \n",
    "    xbar = xdat.mean()\n",
    "    ybar = ydat.mean()\n",
    "\n",
    "    xp = xdat-xbar\n",
    "    yp = ydat-ybar\n",
    "\n",
    "    sum_xp2 = numpy.sum(xp*xp)\n",
    "    sum_yp2 = numpy.sum(yp*yp)\n",
    "    sum_xpyp = numpy.sum(xp*yp)\n",
    "\n",
    "    c1 = pit*sxi*syi*sum_xp2 - numpy.power(sxi,2)*sum_xpyp\n",
    "    c2 = - numpy.power(syi,2)*sum_xp2 + numpy.power(sxi,2)*sum_yp2\n",
    "    c3 = numpy.power(syi,2)*sum_xpyp - pit*sxi*syi*sum_yp2\n",
    "    \n",
    "    ## negative root\n",
    "    bcalc = (-c2 - numpy.sqrt(numpy.power(c2,2)-4*c1*c3)) / 2 / c1 \n",
    "    #balt = (-c2 + numpy.sqrt(numpy.power(c2,2)-4*c1*c3)) / 2 / c1 ### positive root appears to be unumpyhysical\n",
    "\n",
    "    # now that slope is determined, calculate the y intercept\n",
    "    yinter = ybar - bcalc * xbar\n",
    "\n",
    "    # now done, so write back slope\n",
    "    slope = bcalc\n",
    "\n",
    "    # calculate x intercept\n",
    "    xinter = -yinter / slope\n",
    "\n",
    "    return numpy.array(slope), numpy.array(yinter), numpy.array(xinter), xbar, ybar\n",
    "\n",
    "def CalcUnc_Fixed_iv(xdat,sxi,ydat,syi,xbar,ybar,b,pit):\n",
    "    \"\"\"\n",
    "    Calculates the uncertainty of the slope and y\n",
    "    \"\"\"\n",
    "    # backwards compatibility with calcunc\n",
    "    [sxi,syi,pit]=Backwards_Compat(sxi,syi,pit)\n",
    "\n",
    "        \n",
    "    # let us first calculate the derivatives\n",
    "    # dell theta / dell b (dthdb) calculation\n",
    "    wi = Calc_Wi(sxi, syi, b, pit)\n",
    "    sxyi = pit * sxi * syi\n",
    "\n",
    "    ui = xdat - xbar\n",
    "    vi = ydat - ybar\n",
    "    \n",
    "    sum1 = numpy.sum( wi**2. * (2 * b * (ui * vi * sxi**2. - ui**2. * sxyi) + (ui**2. * syi**2. - vi**2 * sxi**2.)) )\n",
    "    sum2 = numpy.sum( wi**3. * (sxyi - b * sxi**2.) * (b**2. * (ui * vi * sxi**2 - ui**2 * sxyi) +\n",
    "                                             b * (ui**2 * syi**2 - vi**2 * sxi**2) -\n",
    "                                             (ui * vi * syi**2 - vi**2 * sxyi)) )\n",
    "    \n",
    "    # sum1 = 0.\n",
    "    # sum2 = 0.\n",
    "    # for it in range(len(xdat)):\n",
    "    #     xi = xdat[it]\n",
    "    #     yi = ydat[it]\n",
    "    #     # sxi = xunc[it]\n",
    "    #     # syi = yunc[it]\n",
    "    #     # pit = p[it]\n",
    "    #     # wi = calc_wi(xunc[it], yunc[it], b, pit)\n",
    "    #     ui = xi - xbar\n",
    "    #     vi = yi - ybar\n",
    "    #     sum1 += wi**2. * (2 * b * (ui * vi * sxi**2. - ui**2. * sxyi) + (ui**2. * syi**2. - vi**2 * sxi**2.))\n",
    "    #     sum2 += wi**3. * (sxyi - b * sxi**2.) * (b**2. * (ui * vi * sxi**2 - ui**2 * sxyi) +\n",
    "    #                                              b * (ui**2 * syi**2 - vi**2 * sxi**2) -\n",
    "    #                                              (ui * vi * syi**2 - vi**2 * sxyi))\n",
    "\n",
    "    dthdb = sum1 + 4. * sum2\n",
    "\n",
    "    # calculate the sum of all weights\n",
    "    wksum = wi * len(xdat)\n",
    "\n",
    "    sxj = sxi\n",
    "    syj = syi\n",
    "    pjt = pit\n",
    "    wj = wi \n",
    "    sxyj = sxyi\n",
    "    uj = xdat - xbar\n",
    "    vj = ydat - ybar\n",
    "            \n",
    "    # now calculate sigasq and sigbsq\n",
    "    sigasq = 0.\n",
    "    sigbsq = 0.\n",
    "    for it in range(len(xdat)):\n",
    "        # calculate dell theta / dell xi and dell theta / dell yi\n",
    "\n",
    "        kron_arr = numpy.array([kron(it,jt) for jt in range(len(xdat))])\n",
    "        dthdxi = numpy.sum( wj**2. * (kron_arr - wi / wksum) * (b**2 * (vj * sxj**2 - 2 * uj * sxyj) +\n",
    "                                                          2 * b * uj * syj**2 - vj * syj**2) ) \n",
    "        # correct equation! not equal to equation 21 in Mahon (1996)\n",
    "        dthdyi = numpy.sum( wj**2. * (kron_arr - wi / wksum) * (b**2 * uj * sxj**2 + 2 * vj * sxyj -\n",
    "                                                            2 * b * vj * sxj**2. - uj * syj**2) ) \n",
    "        # dthdxi = 0.\n",
    "        # dthdyi = 0.\n",
    "        # for jt in range(len(xdat)):\n",
    "        #     # add to dthdxi and dthdyi\n",
    "        #     dthdxi += wj**2. * (kron(it, jt) - wi / wksum) * (b**2 * (vj * sxj**2 - 2 * uj * sxyj) +\n",
    "        #                                                       2 * b * uj * syj**2 - vj * syj**2)\n",
    "        #     # correct equation! not equal to equation 21 in Mahon (1996)\n",
    "        #     dthdyi += wj ** 2. * (kron(it, jt) - wi / wksum) * (b ** 2 * uj * sxj ** 2 + 2 * vj * sxyj -\n",
    "        #                                                        2 * b * vj * sxj**2. - uj * syj ** 2)\n",
    "\n",
    "        # now calculate dell a / dell xi and dell a / dell yi\n",
    "        dadxi = -b * wi / wksum - xbar * dthdxi / dthdb\n",
    "        dadyi = wi / wksum - xbar * dthdyi / dthdb\n",
    "\n",
    "        # now finally add to sigasq and sigbsq\n",
    "        sigbsq += dthdxi**2. * sxi**2. + dthdyi**2. * syi**2. + 2 * sxyi * dthdxi * dthdyi\n",
    "        sigasq += dadxi**2. * sxi**2. + dadyi**2. * syi**2. + 2 * sxyi * dadxi * dadyi\n",
    "\n",
    "    # now divide sigbsq\n",
    "    sigbsq /= dthdb**2.\n",
    "\n",
    "    yinterunc = numpy.sqrt(sigasq)\n",
    "    slopeunc = numpy.sqrt(sigbsq)\n",
    "\n",
    "    return numpy.array(slopeunc), numpy.array(yinterunc) \n",
    "\n",
    "def Backwards_Compat(sxi,syi,pit):\n",
    "    try:\n",
    "        if len(pit)>1: pit=pit[0]\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        if len(syi)>1: syi=syi[0]\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "        if len(sxi)>1: sxi=sxi[0]\n",
    "    except:\n",
    "        pass\n",
    "    return sxi,syi,pit\n",
    "\n",
    "def CalcMswd_Fixed_iv(xdat, sxi, ydat, syi, pit, slope, yinter ):\n",
    "    [sxi,syi,pit]=backwards_compat(sxi,syi,pit)\n",
    "        \n",
    "    wi = Calc_Wi(sxi, syi, slope, pit)\n",
    "    mswd = numpy.sum( wi * ((ydat - slope*xdat - yinter)**2.)) / (len(xdat) - 2.)\n",
    "    # now divide by degrees of freedom minus 2, since 2 fixed parameters\n",
    "    return mswd\n",
    "\n",
    "def Calc_Wi(sx, sy, b, p):\n",
    "    return 1. / (sy**2 + b**2 * sx**2 - 2 * b * p * sx * sy)\n",
    "\n",
    "\n",
    "def kron(i, j):\n",
    "    # calculates Kronecker delta\n",
    "    if i == j:\n",
    "        return 1.\n",
    "    else:\n",
    "        return 0.\n",
    "\n",
    "\n",
    "# example of implementation\n",
    "#slope1, yinter1, xinter1, xbar1, ybar1 = calcparams_fixed_iv(xdat,xunc,ydat,yunc,p)\n",
    "#slope1unc, yinter1unc = calcunc_fixed_iv(xdat,xunc,ydat,yunc,xbar1,ybar1,slope1,p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7661f985",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Regression Line using York Regression\n",
    "def New_York_Reg(x,y,Corr,Std_x,Std_y):\n",
    "    N = len(x)\n",
    "# Just in case they didn't agree (e.g., MPIESM11)\n",
    "    x = numpy.array(x)\n",
    "    y = numpy.array(y)\n",
    "    Slope, Intercept, xinter1, xbar1, ybar1 = CalcParams_Fixed_iv(x,Std_x,y,Std_y,Corr)\n",
    "#\n",
    "## Calculate Predictions for Plotting\n",
    "    Predictions = numpy.array([[numpy.min(x), numpy.max(x)], \\\n",
    "    [numpy.min(x) * Slope + Intercept, numpy.max(x) * Slope + Intercept]])\n",
    "#\n",
    "## Calculate Error Bars\n",
    "## t-statistic for N-2 dof at 84% confidence: appropriate for comparing overlap \n",
    "    Z84 = stats.t.ppf(0.84, N-2)\n",
    "    Slope1unc, yInter1unc = CalcUnc_Fixed_iv(x,numpy.array(Std_x),y,numpy.array(Std_y),xbar1,ybar1,Slope,numpy.array(Corr))\n",
    "    Error_Bar = Slope1unc * Z84\n",
    "#\n",
    "## Return Output\n",
    "    return [Slope, Intercept, Error_Bar, Predictions]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e3b220-d578-4669-a9cc-2f73b139aa4a",
   "metadata": {},
   "source": [
    "## calculate T,P correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a06fb581-efef-4a8e-9dcc-f5df83923dde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MPIESM12',\n",
       " 'MPIESM11',\n",
       " 'IPSLCM5A',\n",
       " 'HadGEM2',\n",
       " 'HadCM3L',\n",
       " 'GISSE2R',\n",
       " 'FAMOUS',\n",
       " 'ECHAM5MPIOM',\n",
       " 'CNRMCM61',\n",
       " 'CESM104',\n",
       " 'CCSM3II',\n",
       " 'CCSM3']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Model_List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "155bb1b1-5bdb-430c-9de1-713fbf05ae63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Precipitation Anomaly VS Temperature Anomaly Graph For All 12 Models\n",
    "Precip_1_21_151_Slopes = numpy.zeros((12,3))\n",
    "Precip_1_21_151_Error_Bars = numpy.zeros((12,3))\n",
    "Precip_Corr_array = numpy.zeros((12,1))\n",
    "\n",
    "i = 0\n",
    "j = -1\n",
    "Count = -1\n",
    "for Model in list(Model_List):\n",
    "    if j < 2:\n",
    "        j += 1\n",
    "    else:\n",
    "        j = 0\n",
    "        i += 1\n",
    "    Count += 1\n",
    "#    Axes = Fig.add_subplot(4,3, Count)\n",
    "#\n",
    "# Open Temperature Control and Temperature 4x Files Using Function\n",
    "    Temp_Control, Years_Control, Temp_4x, Years_4x = Open_Temp_Files(Temp_Files, Model)\n",
    "#\n",
    "# Create Smoothen Temperature 4x and Control Lines Using Function\n",
    "    Temp_Control_Smooth = Temp_Smooth(Temp_Control, Years_Control, Temp_4x, Years_4x, Model)\n",
    "#\n",
    "# Calculate Temperature Anomaly\n",
    "    Temp_Anomaly = Temp_4x - Temp_Control_Smooth\n",
    "#\n",
    "# Open Precipitation Control and Precipitation 4x Files Using Function\n",
    "    Precip_Control, Years_Control, Precip_4x, Years_4x = Open_Precip_Files(Precip_Files, Model)\n",
    "#\n",
    "# Create Smoothen Precipitation 4x and Control Lines Using Function\n",
    "    Precip_Control_Smooth = Precip_Smooth(Precip_Control, Years_Control, Precip_4x, Years_4x, Model)\n",
    "#\n",
    "# Calculate Precipitation Anomaly\n",
    "    Precip_Control =  Precip_Control * L_Vapour\n",
    "    Precip_Anomaly = (Precip_4x - Precip_Control_Smooth) * L_Vapour\n",
    "    if Model==\"CCSM3II\":\n",
    "        Precip_Anomaly = Precip_Anomaly * 1000\n",
    "#\n",
    "# Calculate Correlation and Standard Deviations\n",
    "    PI_Len = numpy.min([len(Temp_Control),len(Precip_Control)])\n",
    "    Precip_Corr = Corr_IgnoreNaN(Temp_Control[:PI_Len],Precip_Control[:PI_Len])\n",
    "    Precip_Std_x = float(numpy.std(Temp_Control))\n",
    "    Precip_Std_y = float(numpy.std(Precip_Control))\n",
    "\n",
    "# Store Correlation in  Array\n",
    "    Precip_Corr_array[Count][0] = Precip_Corr\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4e232202-3ee2-4688-bf0d-3ec674fe0aee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.50074918],\n",
       "       [ 0.4802978 ],\n",
       "       [ 0.58541757],\n",
       "       [ 0.70582386],\n",
       "       [ 0.46451961],\n",
       "       [-0.01958851],\n",
       "       [ 0.73188028],\n",
       "       [ 0.89833324],\n",
       "       [ 0.828817  ],\n",
       "       [ 0.71648305],\n",
       "       [ 0.66198156],\n",
       "       [ 0.62796933]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Precip_Corr_array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2834468a-2963-4876-8430-5c7f8b48268a",
   "metadata": {},
   "source": [
    "## calculate T,N correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3cd8af63-824d-4211-b746-a5d993021140",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Net TOA Flux Anomaly VS Temperature Anomaly Graph For All 12 Models\n",
    "Net_TOA_1_21_151_Slopes = numpy.zeros((12,3))\n",
    "Net_TOA_1_21_151_Error_Bars = numpy.zeros((12,3))\n",
    "Net_TOA_Corr_array = numpy.zeros((12,1))\n",
    "\n",
    "i = 0\n",
    "j = -1\n",
    "Count = -1\n",
    "for Model in list(Model_List):\n",
    "    if j < 2:\n",
    "        j += 1\n",
    "    else:\n",
    "        j = 0\n",
    "        i += 1\n",
    "    Count += 1\n",
    "#    Axes = Fig.add_subplot(4,3, Count)\n",
    "#\n",
    "# Open Temperature Control and Temperature 4x Files Using Function\n",
    "    Temp_Control, Years_Control, Temp_4x, Years_4x = Open_Temp_Files(Temp_Files, Model)\n",
    "#\n",
    "# Create Smoothen Temperature 4x and Control Lines Using Function\n",
    "    Temp_Control_Smooth = Temp_Smooth(Temp_Control, Years_Control, Temp_4x, Years_4x, Model)\n",
    "#\n",
    "# Calculate Temperature Anomaly\n",
    "    Temp_Anomaly = Temp_4x - Temp_Control_Smooth\n",
    "#\n",
    "# Open Net TOA Flux Control and Net TOA Flux 4x Files Using Function\n",
    "    Net_TOA_Control, Years_Control, Net_TOA_4x, Years_4x = Open_Net_TOA_Files(Net_TOA_Files, Model)\n",
    "#\n",
    "# Create Smoothen Net TOA Flux 4x and Control Lines Using Function\n",
    "    Net_TOA_Control_Smooth = Net_TOA_Smooth(Net_TOA_Control, Years_Control, Net_TOA_4x, Years_4x, Model)\n",
    "#\n",
    "# Calculate Net TOA Flux Anomaly\n",
    "    Net_TOA_Anomaly = Net_TOA_4x - Net_TOA_Control_Smooth\n",
    "#\n",
    "# Calculate Correlation and Standard Deviations\n",
    "    if Model != \"CCSM3\":\n",
    "        PI_Len = numpy.min([len(Temp_Control),len(Net_TOA_Control)])\n",
    "        Net_TOA_Corr = Corr_IgnoreNaN(Temp_Control[:PI_Len],Net_TOA_Control[:PI_Len])\n",
    "        Net_TOA_Std_x = float(numpy.std(Temp_Control))\n",
    "        Net_TOA_Std_y = float(numpy.std(Net_TOA_Control))\n",
    "\n",
    "\n",
    "# Store Correlation in  Array\n",
    "    #Precip_Corr_array[Count][0] = Precip_Corr\n",
    "    Net_TOA_Corr_array[Count][0] = Net_TOA_Corr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "487117b3-dcdb-4df9-a1d0-e454bedb152b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.47561917],\n",
       "       [-0.49433414],\n",
       "       [-0.05183391],\n",
       "       [-0.13822923],\n",
       "       [-0.18821027],\n",
       "       [-0.24404411],\n",
       "       [-0.12120815],\n",
       "       [-0.22915201],\n",
       "       [-0.38550431],\n",
       "       [-0.35466603],\n",
       "       [-0.20753318],\n",
       "       [-0.20753318]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Net_TOA_Corr_array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4489019",
   "metadata": {},
   "source": [
    "## print table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0040ffcb-219a-42ee-a2ae-91d8c5ed0f2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>r(T,P)</th>\n",
       "      <th>r(T,N)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MPIESM12</td>\n",
       "      <td>0.50</td>\n",
       "      <td>-0.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MPIESM11</td>\n",
       "      <td>0.48</td>\n",
       "      <td>-0.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IPSLCM5A</td>\n",
       "      <td>0.59</td>\n",
       "      <td>-0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HadGEM2</td>\n",
       "      <td>0.71</td>\n",
       "      <td>-0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HadCM3L</td>\n",
       "      <td>0.46</td>\n",
       "      <td>-0.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GISSE2R</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>-0.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>FAMOUS</td>\n",
       "      <td>0.73</td>\n",
       "      <td>-0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ECHAM5MPIOM</td>\n",
       "      <td>0.90</td>\n",
       "      <td>-0.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>CNRMCM61</td>\n",
       "      <td>0.83</td>\n",
       "      <td>-0.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>CESM104</td>\n",
       "      <td>0.72</td>\n",
       "      <td>-0.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>CCSM3II</td>\n",
       "      <td>0.66</td>\n",
       "      <td>-0.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>CCSM3</td>\n",
       "      <td>0.63</td>\n",
       "      <td>-0.21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Model  r(T,P)  r(T,N)\n",
       "0      MPIESM12    0.50   -0.48\n",
       "1      MPIESM11    0.48   -0.49\n",
       "2      IPSLCM5A    0.59   -0.05\n",
       "3       HadGEM2    0.71   -0.14\n",
       "4       HadCM3L    0.46   -0.19\n",
       "5       GISSE2R   -0.02   -0.24\n",
       "6        FAMOUS    0.73   -0.12\n",
       "7   ECHAM5MPIOM    0.90   -0.23\n",
       "8      CNRMCM61    0.83   -0.39\n",
       "9       CESM104    0.72   -0.35\n",
       "10      CCSM3II    0.66   -0.21\n",
       "11        CCSM3    0.63   -0.21"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create DataFrame With correlations\n",
    "Correlations_Compare = pandas.DataFrame({\"Model\": Model_List, \"r(T,P)\": numpy.squeeze(Precip_Corr_array.round(2)), \\\n",
    "\"r(T,N)\": numpy.squeeze(Net_TOA_Corr_array.round(2))})\n",
    "Correlations_Compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b4cd39c6-c236-405d-9cfb-e148bc77510f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Filename_1 = \"./\"+\"CSV/\"+\"Correlations.csv\"\n",
    "Correlations_Compare.to_csv(Filename_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf7b40c-6947-427a-b0e7-8af40b352bc4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
